{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular la Agregación de Opporunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.location_notebook import get_location\n",
    "import src.features.build_features as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "(DATA_DIR, DATA_DIR_PROCESSED, \n",
    "INTERMEDIATE_RESULTS, GROUP_INTERMEDIATE_RESULTS, \n",
    "CLEANED_DS , TRAIN_RAW_FILE, \n",
    "VALIDATION_RAW_FILE, TEMPLATE_SUBMIT) = get_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(INTERMEDIATE_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregación\n",
    "- El dataset tiene varios registros para cada oportunidad. \n",
    "- se reagrupará la oportunidad con las variables que se modifican entre los grupos\n",
    "    - para ello, vamos a buscar las columnas que cambian al reagrupar\n",
    "- Luego de realizar la agregación, tendremos una sola fila con:\n",
    "    - todos los productos que compró\n",
    "    - todos las familias de productos que compró\n",
    "    - Planned_Range mean y std\n",
    "    - Total_Amount acumulado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrupar por: TRF\n",
      "Agrupar por: Planned_Range_days\n",
      "Agrupar por: Planned_Delivery_Start_Date_Period\n",
      "Agrupar por: Planned_Delivery_Start_Date_Year\n",
      "Agrupar por: Planned_Delivery_Start_Date_Month\n",
      "Agrupar por: Planned_Delivery_Start_Date_Q1_Quarter\n",
      "Agrupar por: Planned_Delivery_Start_Date_Q2_Quarter\n",
      "Agrupar por: Planned_Delivery_Start_Date_Q3_Quarter\n",
      "Agrupar por: Planned_Delivery_Start_Date_Q4_Quarter\n",
      "Agrupar por: Planned_Delivery_End_Date_Period\n",
      "Agrupar por: Planned_Delivery_End_Date_Year\n",
      "Agrupar por: Planned_Delivery_End_Date_Month\n",
      "Agrupar por: Planned_Delivery_End_Date_Q1_Quarter\n",
      "Agrupar por: Planned_Delivery_End_Date_Q2_Quarter\n",
      "Agrupar por: Planned_Delivery_End_Date_Q3_Quarter\n",
      "Agrupar por: Planned_Delivery_End_Date_Q4_Quarter\n",
      "Agrupar por: Planned_Delivery_End_Date_Imputed\n"
     ]
    }
   ],
   "source": [
    "# buscamos las columnas que cambian\n",
    "oc = df_train.columns[~df_train.columns.isin(np.append(prod_cols, [ \"Opportunity_ID\" ]))].to_numpy() \n",
    "for c in oc:\n",
    "    if (df_train[['Opportunity_ID', c]].drop_duplicates().shape[0] != df_train.Opportunity_ID.nunique()): print(f\"Agrupar por: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_train.groupby('Opportunity_ID').ASP_was_converted.nunique() > 1).reset_index().groupby('ASP_was_converted').Opportunity_ID.unique().iloc[1]\n",
    "# df_train.loc[df_train.Opportunity_ID == 1694,[\"Total_Amount_Currency\", \"ASP_was_converted\", \"rate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_train.groupby('Opportunity_ID').Total_Amount_Imputed.nunique() > 1).reset_index().groupby('Total_Amount_Imputed').Opportunity_ID.unique().iloc[1]\n",
    "# df_train.loc[df_train.Opportunity_ID == 1694,[\"Total_Amount_Currency\", \"ASP_was_converted\", \"rate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = bf.product_agg(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(GROUP_INTERMEDIATE_RESULTS, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "### Legacy Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_cols = [ \n",
    "#     \"Total_Amount\", \n",
    "#     \"TRF\",\n",
    "#     \"Planned_Range_days_mean\",\n",
    "#     \"Planned_Range_days_std\",\n",
    "\n",
    "#     \"Planned_Delivery_Start_Date_Period_mean\",\n",
    "#     \"Planned_Delivery_Start_Date_Period_std\",\n",
    "#     \"Planned_Delivery_Start_Date_Year_mean\",\n",
    "#     \"Planned_Delivery_Start_Date_Year_std\",\n",
    "#     \"Planned_Delivery_Start_Date_Month_mean\",\n",
    "#     \"Planned_Delivery_Start_Date_Month_std\",\n",
    "#     \"Planned_Delivery_Start_Date_Quarter_mean\", # ?\n",
    "#     \"Planned_Delivery_Start_Date_Quarter_std\", # ?\n",
    "    \n",
    "#     \"Planned_Delivery_End_Date_Period_mean\",\n",
    "#     \"Planned_Delivery_End_Date_Period_std\",\n",
    "#     \"Planned_Delivery_End_Date_Year_mean\",\n",
    "#     \"Planned_Delivery_End_Date_Year_std\",\n",
    "#     \"Planned_Delivery_End_Date_Month_mean\",\n",
    "#     \"Planned_Delivery_End_Date_Month_std\",\n",
    "#     \"Planned_Delivery_End_Date_Quarter_mean\", # ?\n",
    "#     \"Planned_Delivery_End_Date_Quarter_std\", # ?\n",
    "# ]\n",
    "\n",
    "# agg_planned_cols = [\n",
    "#     \"Planned_Range_days\",\n",
    "#     \"Planned_Delivery_Start_Date_Period\",\n",
    "#     \"Planned_Delivery_Start_Date_Year\",\n",
    "#     \"Planned_Delivery_Start_Date_Month\",\n",
    "#     \"Planned_Delivery_Start_Date_Quarter\",\n",
    "#     \"Planned_Delivery_End_Date_Period\",\n",
    "#     \"Planned_Delivery_End_Date_Year\",\n",
    "#     \"Planned_Delivery_End_Date_Month\",\n",
    "#     \"Planned_Delivery_End_Date_Quarter\",\n",
    "# ]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def aggregate_data(df, prod_cols):\n",
    "#     res = pd.DataFrame([], columns=np.append(prod_cols, agg_cols + [\"Opportunity_ID\"]))\n",
    "#     accum = []\n",
    "#     for key, group in tqdm(df.groupby('Opportunity_ID')):\n",
    "#         s = group[np.append(prod_cols, [ \"Total_Amount\", \"TRF\" ])].sum()\n",
    "        \n",
    "#         planned_range = group.agg({c:[\"std\", \"mean\"] for c in agg_planned_cols})\n",
    "#         for c in agg_planned_cols:\n",
    "#             s = s.append(pd.Series(planned_range[[c]].loc[\"mean\"].fillna(0).iloc[0], index=[c+\"_mean\"]))\n",
    "#             s = s.append(pd.Series(planned_range[[c]].loc[\"std\"].fillna(0).iloc[0], index=[c+\"_std\"]))\n",
    "\n",
    "#         s = s.append(pd.Series([key], index=[\"Opportunity_ID\"]))\n",
    "#         accum.append(s)\n",
    "#     res = res.append(accum, ignore_index=True)\n",
    "#     return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "si es la primera vez que se ejecutan, quitar el script false, ya que es una operación que demanda mucho tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# agg_train = aggregate_data(df_train, prod_cols)\n",
    "# agg_val = aggregate_data(df_val, prod_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "# este en el caso que ya se haya ejecutado, leer el resultado\n",
    "# agg_train = pd.read_parquet(os.path.join(DATA_DIR,\"processed/intermediate_group_result_train.parquet\"))\n",
    "# agg_val = pd.read_parquet(os.path.join(DATA_DIR,\"processed/intermediate_group_result_val.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_train.shape, agg_val.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
